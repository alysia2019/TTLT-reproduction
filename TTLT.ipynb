{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required packages\n",
    "## Base modules\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Encoding Modules\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check local GPU is running, uncomment and run if using a local GPU\n",
    "#torch.cuda.current_device()\n",
    "#torch.cuda.device(0)\n",
    "#torch.cuda.device_count()\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll build a helper function to generate simulated reads.\n",
    "## Could've gone for specifying probabilities per base,\n",
    "## but as it's a field test we're keeping it simple.\n",
    "\n",
    "def random_dna_sequence(length):\n",
    "    return np.array(list(''.join(random.choice('ACTG') for _ in range(length))))\n",
    "\n",
    "# Function for generating n x m R matrix,\n",
    "# where n is the number of reads (total_reads)\n",
    "# and m is each read's length (read_length).\n",
    "\n",
    "def create_read_matrix(total_reads,read_length):\n",
    "    \n",
    "    read_matrix = []\n",
    "    \n",
    "    for i in range(total_reads):\n",
    "        read_matrix.append(random_dna_sequence(read_length))\n",
    "        \n",
    "    return np.vstack(read_matrix)\n",
    "\n",
    "#Build a function that simultaneously generates unique, desired length k-mers \n",
    "##from a previously generated read_matrix and times said k-mer occured.\n",
    "## Returns both objects ordered by occurence\n",
    "\n",
    "def create_kmer_matrix(read_matrix,kmer_size):\n",
    "    \n",
    "    kmer_matrix = []\n",
    "    \n",
    "    for i in range(read_matrix.shape[0]):\n",
    "        \n",
    "        for j in range(len(read_matrix[i])-kmer_size+1):\n",
    "            kmer_matrix.append(read_matrix[i][j:j+kmer_size])\n",
    "            \n",
    "    kmer_matrix, counts = np.unique(kmer_matrix,axis=0,return_counts=1)\n",
    "    #inner index to sort by count occurences\n",
    "    sort_index = np.argsort(-counts)\n",
    "    \n",
    "    return kmer_matrix[sort_index], counts[sort_index]\n",
    "\n",
    "## function to turn our kmer matrix into a one hot matrix.\n",
    "\n",
    "def oneshotonehot(kmer_matrix):\n",
    "    \n",
    "    # Not yet robust, breaks when single vector is entered;\n",
    "    # look into reshaping\n",
    "    \n",
    "    #Define bases and fit labels to use\n",
    "    \n",
    "    vectors = kmer_matrix[0]\n",
    "    counts = kmer_matrix[1]\n",
    "    oneshotonehot_matrix = []\n",
    "    bases = ['A','C','T','G']\n",
    "    label_encoder = LabelEncoder()\n",
    "    base_encoder = label_encoder.fit(bases)\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        \n",
    "        encoded_base_seq = base_encoder.transform(vectors[i])\n",
    "        reshaped_vector = encoded_base_seq.reshape(-1)\n",
    "        one_hot_vector = np.eye(len(bases))[reshaped_vector] \n",
    "        oneshotonehot_matrix.append(one_hot_vector)\n",
    "        \n",
    "    return oneshotonehot_matrix, counts\n",
    "\n",
    "## One final wrapper function to generate per-sample data on the spot\n",
    "\n",
    "def generate_kmer_data(total_reads, read_length, kmer_size, number_of_samples):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    sample_num = [] \n",
    "    \n",
    "    for i in range(number_of_samples):\n",
    "        \n",
    "        read_matrix = create_read_matrix(total_reads,read_length)\n",
    "        kmer_matrix = create_kmer_matrix(read_matrix,kmer_size)\n",
    "        onehot_matrix = oneshotonehot(kmer_matrix)\n",
    "        X.extend(onehot_matrix[0])\n",
    "        Y.extend(onehot_matrix[1])\n",
    "        sample_num.extend([i+1] * len(onehot_matrix[0]))\n",
    "        \n",
    "    return X, Y, sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now generate and load data with our previously created helper functions\n",
    "## X corresponds to one-hot encoded sequence vectors per kmer sequence\n",
    "## Y corresponds to the number of times said kmer was counted\n",
    "## sample corresponds to the sample identifier\n",
    "\n",
    "## We'll import modules to help split our data into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y, sample = generate_kmer_data(total_reads = 100, read_length = 10 , kmer_size = 5, number_of_samples=2)\n",
    "\n",
    "\n",
    "## Before proceeding, we'll concatenate X and it's corresponding sample label.\n",
    "\n",
    "\n",
    "# Initial split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "# Splitting training values to obtain a validation set \n",
    "## Computing validation set from the previously computed 80% training data\n",
    "## 25% \"test\" on this validation split amounts to 20% of overall data \n",
    "## Training is the 60% remaining\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-82af327f462d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Build LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "## Pytorch NN modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "\n",
    "## Define optimizer, RMSprop as per TTLT\n",
    "## Model was trained for 200 epochs\n",
    "## Learning rate = 0.001, alpha = 0.99, momentum = 0\n",
    "### alpha and momentum correspond to pytorch's default value\n",
    "### for the torch.optim.RMSprop class; \n",
    "### therefore, we'll only specify learning rat and epochs.\n",
    "n_epoch = 200\n",
    "learning_rate = 0.001\n",
    "optim.RMSprop()\n",
    "\n",
    "# Build LSTM\n",
    "## Layers = 2, 256 hidden units per layer.\n",
    "## Embedding output size = 2\n",
    "\n",
    "bi_lstm = nn.LSTM(input_size=24, hidden_size = 256 , num_layers = 2, bidirectional=True)\n",
    "reverse_lstm = nn.LSTM(input_size=24, hidden_size = 256 , num_layers = 2, bidirectional=True)\n",
    "\n",
    "\n",
    "bi_output, bi_hidden = bi_lstm()\n",
    "reverse_output, reverse_hidden = bi_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prediction layer\n",
    "## MLP\n",
    "## layers = 2, sizes 150 and 100, respectively\n",
    "## Activation function = ReLU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
